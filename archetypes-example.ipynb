{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6f05554-993e-4ec0-bba0-2010dae3a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that this whole thing will run a whole lot faster if you have CUDA set up.\n",
    "#! pip install -U archetyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e1bf1a5-bfcd-40d6-a96e-ed6c979c4d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# for development, we try to import first from the src folder\n",
    "try:\n",
    "    from src.archetypes.archetypes import ArchetypeCollection, ArchetypeQuantifier\n",
    "\n",
    "# if this fails, we just import as we normally would when the package is installed\n",
    "except:\n",
    "    from archetypes.archetypes import ArchetypeCollection, ArchetypeQuantifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d52258c3-ca8a-4eb6-b7bd-2c3a21df36ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model that we would like to use for our analyses\n",
    "model_name = 'sentence-transformers/all-roberta-large-v1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c72a05-41ef-48dc-b8b6-4e9491b1282d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archetype added: Acquired Capability - Ideation/Simulation\n",
      "Archetype added: Perceived Burdensomness\n",
      "Archetype added: Thwarted Belongingness\n"
     ]
    }
   ],
   "source": [
    "# There are two ways in which we can create \"Archetypes\" from prototypical sentences. \n",
    "\n",
    "# The first method, which is a more manual approach, is to instantiate a member of our Archetype_Collection class.\n",
    "# Then, we can individually add prototype sentences that are mapped to constructs.\n",
    "archetypes = ArchetypeCollection()\n",
    "\n",
    "archetypes.add_archetype(name=\"Acquired Capability - Ideation/Simulation\",\n",
    "                         sentences = [\"I think about putting a rope around my neck\",\n",
    "                                      \"I want to put a gun in my mouth and pull the trigger\",\n",
    "                                      \"I plan on taking a bunch of pills and just fall asleep forever\"])\n",
    "\n",
    "archetypes.add_archetype(name=\"Perceived Burdensomness\",\n",
    "                         sentences = [\"The world would be a better place without me\",\n",
    "                                      \"I add nothing to the world\",\n",
    "                                      \"Things would be better if I was not here.\"])\n",
    "\n",
    "archetypes.add_archetype(name=\"Thwarted Belongingness\",\n",
    "                         sentences = [\"I am alone\",\n",
    "                                      \"I don't fit in anywhere\",\n",
    "                                      \"Everyone hates me\"])\n",
    "\n",
    "#... and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11fcafa6-3d20-4def-9a4e-592cee4fd814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archetype added: Acquired Capability - Ideation/Simulation\n",
      "Archetype added: Acquired Capability - Experiences of Endurance\n",
      "Archetype added: Acquired Capability - Desensitization to Harm\n",
      "Archetype added: Acquired Capability - High Tolerance for Physical Pain\n",
      "Archetype added: Acquired Capability - Engagement in Risky Behaviors\n",
      "Archetype added: Acquired Capability - Familiarity with Self-Harm Methods\n",
      "Archetype added: Perceived Burdensomness\n",
      "Archetype added: Thwarted Belongingness\n"
     ]
    }
   ],
   "source": [
    "# The second, and \"cleaner\" method, is to load them from a CSV file, as we're doing here.\n",
    "\n",
    "# instantiate a member of our Archetype_Collection class\n",
    "archetypes = ArchetypeCollection()\n",
    "\n",
    "# load in our archetypes from a CSV file\n",
    "archetypes.add_archetypes_from_CSV(filepath=\"example_archetypes/Suicidality-Archetypes.csv\",\n",
    "                                   file_encoding=\"utf-8-sig\",\n",
    "                                   file_has_headers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8fd71b5-24d9-47d9-91cf-e1c7274a2844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArchetypeQuantifier has been successfully instantiated.\n"
     ]
    }
   ],
   "source": [
    "# Now, we can initialize an ArchetypeQuantifier with the archetypes that we set up above\n",
    "archetype_quantifier = ArchetypeQuantifier(archetypes=archetypes,\n",
    "                                           model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f8a35a9-3c44-4aee-b113-27bd09807530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Acquired Capability - Ideation/Simulation',\n",
       " 'Acquired Capability - Experiences of Endurance',\n",
       " 'Acquired Capability - Desensitization to Harm',\n",
       " 'Acquired Capability - High Tolerance for Physical Pain',\n",
       " 'Acquired Capability - Engagement in Risky Behaviors',\n",
       " 'Acquired Capability - Familiarity with Self-Harm Methods',\n",
       " 'Perceived Burdensomness',\n",
       " 'Thwarted Belongingness']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the archetype names and the order they appear in\n",
    "archetype_quantifier.get_list_of_archetypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba2f90b2-88cd-40c0-b0a6-ba722f05a4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully exported intra-archetype cosine similarity matrix for: Acquired Capability - Ideation/Simulation\n",
      "Successfully exported intra-archetype cosine similarity matrix for: Acquired Capability - Experiences of Endurance\n",
      "Successfully exported intra-archetype cosine similarity matrix for: Acquired Capability - Desensitization to Harm\n",
      "Successfully exported intra-archetype cosine similarity matrix for: Acquired Capability - High Tolerance for Physical Pain\n",
      "Successfully exported intra-archetype cosine similarity matrix for: Acquired Capability - Engagement in Risky Behaviors\n",
      "Successfully exported intra-archetype cosine similarity matrix for: Acquired Capability - Familiarity with Self-Harm Methods\n",
      "Successfully exported intra-archetype cosine similarity matrix for: Perceived Burdensomness\n",
      "Successfully exported intra-archetype cosine similarity matrix for: Thwarted Belongingness\n"
     ]
    }
   ],
   "source": [
    "# Here, we're going to do a few things to get a descriptive sense of the psychometrics of our archetypes.\n",
    "# First, let's just get item-level correlations for all of our archetypes. We need to specify\n",
    "# the output folder that we would like to export our correlation matrices into.\n",
    "archetype_quantifier.export_intra_archetype_correlations(output_folder=\"ItemCorrelations/\",\n",
    "                                                            mean_center_vectors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19a96cb6-360e-416a-8c35-6cffeb4dd790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating all relationships within/across all archetypes...\n",
      "All relationships exported to: ItemCorrelations/All_Archetype_Relationships.csv\n"
     ]
    }
   ],
   "source": [
    "# What if we want to look at the relationships across all archetypes and their constitutent prototypical sentences?\n",
    "# Why, we can do that! What an exciting time to be alive!\n",
    "archetype_quantifier.export_all_archetype_relationships(output_file_location=\"ItemCorrelations/All_Archetype_Relationships.csv\",\n",
    "                                                        mean_center_vectors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "894b0aba-f989-40db-9493-71a54850cb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All archetype vectors have been exported.\n"
     ]
    }
   ],
   "source": [
    "# What if we want to actually get the raw vectors for each archetype/prototype? We can do that too!\n",
    "# You might want to do this, for example, to run something like a confirmatory factor analysis to\n",
    "# sanity check the structure of your archetypes.\n",
    "archetype_quantifier.export_all_archetype_vectors(output_file_location=\"ItemCorrelations/Archetype_Vectors.csv\",\n",
    "                                                  mean_center_vectors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f9de3c6-d448-45bb-85c9-b64d748b6b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Acquired Capability - Ideation/Simulation...\n",
      "\t0.78127: I think about putting a rope around my neck\n",
      "\t0.80222: I want to put a gun in my mouth and pull the trigger\n",
      "\t0.75624: I plan on taking a bunch of pills and just fall asleep forever\n",
      "\t--------------------\n",
      "\t0.77991: Average item-rest correlation\n",
      "\t0.67798: Cronbach's alpha\n",
      "\n",
      "\n",
      "Evaluating Acquired Capability - Experiences of Endurance...\n",
      "\t0.86638: I've been through so much pain in my life that I feel like nothing can hurt me anymore\n",
      "\t0.81043: Overcoming those challenges made me realize I can endure a lot more than I thought.\n",
      "\t0.85491: I've become numb to the pain and it takes a lot to bother me now.\n",
      "\t--------------------\n",
      "\t0.84391: Average item-rest correlation\n",
      "\t0.79793: Cronbach's alpha\n",
      "\n",
      "\n",
      "Evaluating Acquired Capability - Desensitization to Harm...\n",
      "\t0.80566: I've seen and experienced so much violence that it doesn't faze me anymore.\n",
      "\t0.80979: I can handle situations that used to terrify me, it's like I'm immune to the fear.\n",
      "\t0.75562: I've become desensitized to the pain\n",
      "\t--------------------\n",
      "\t0.79036: Average item-rest correlation\n",
      "\t0.69957: Cronbach's alpha\n",
      "\n",
      "\n",
      "Evaluating Acquired Capability - High Tolerance for Physical Pain...\n",
      "\t0.92195: I can tolerate physical pain much better now; it's almost like I've trained myself.\n",
      "\t0.92411: I've intentionally exposed myself to pain to build up my resistance.\n",
      "\t0.89392: I've been through so many injuries that pain doesn't bother me as much.\n",
      "\t--------------------\n",
      "\t0.91333: Average item-rest correlation\n",
      "\t0.9006: Cronbach's alpha\n",
      "\n",
      "\n",
      "Evaluating Acquired Capability - Engagement in Risky Behaviors...\n",
      "\t0.90614: I've taken risks that others wouldn't even consider; it's like I'm not afraid of consequences anymore.\n",
      "\t0.92858: Engaging in extreme activities has made me less afraid of potential harm.\n",
      "\t0.93639: I've deliberately put myself in dangerous situations, and it doesn't scare me like it used to.\n",
      "\t--------------------\n",
      "\t0.9237: Average item-rest correlation\n",
      "\t0.91399: Cronbach's alpha\n",
      "\n",
      "\n",
      "Evaluating Acquired Capability - Familiarity with Self-Harm Methods...\n",
      "\t0.83032: I've researched and learned about different ways to harm myself\n",
      "\t0.86312: Knowing about self-harm methods doesn't bother me\n",
      "\t0.85819: I'm not disturbed by the idea of self-harm anymore\n",
      "\t--------------------\n",
      "\t0.85054: Average item-rest correlation\n",
      "\t0.80884: Cronbach's alpha\n",
      "\n",
      "\n",
      "Evaluating Perceived Burdensomness...\n",
      "\t0.87785: Everyone would be better off without me\n",
      "\t0.90788: The world would be a better place without me\n",
      "\t0.75336: I add nothing to the world\n",
      "\t0.81403: Things would be better if I was not here.\n",
      "\t--------------------\n",
      "\t0.83828: Average item-rest correlation\n",
      "\t0.85898: Cronbach's alpha\n",
      "\n",
      "\n",
      "Evaluating Thwarted Belongingness...\n",
      "\t0.75242: I am alone\n",
      "\t0.79965: I don't fit in anywhere\n",
      "\t0.78758: Everyone hates me\n",
      "\t--------------------\n",
      "\t0.77988: Average item-rest correlation\n",
      "\t0.67792: Cronbach's alpha\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now, let's evaluate the \"internal consistency\" of our archetypes in a rough, Boyd-esque fashion.\n",
    "archetype_quantifier.evaluate_archetype_consistency(mean_center_vectors=True)\n",
    "\n",
    "# In theory, we're looking for Cronbach's alpha / item-rest cosine similarities in the neighborhood of >= .70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3be33e27-9e20-4ba8-8280-435d81852cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>tait_sa</td>\n",
       "      <td>1.454254e+09</td>\n",
       "      <td>43jg8v</td>\n",
       "      <td>Troubled</td>\n",
       "      <td>Life is hell. \\r\\n\\r\\nI know that is a common ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>Sadnessforevert</td>\n",
       "      <td>1.454255e+09</td>\n",
       "      <td>43jh28</td>\n",
       "      <td>No friends for over 8 years...I need to die</td>\n",
       "      <td>Raised in an abusive family, I have had 3 boyf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>Thisexistencehurts</td>\n",
       "      <td>1.454257e+09</td>\n",
       "      <td>43jm4b</td>\n",
       "      <td>Anyone else out there that would have ended it...</td>\n",
       "      <td>My family is the only reason I havent killed m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>Rhexysexy</td>\n",
       "      <td>1.454257e+09</td>\n",
       "      <td>43jnbl</td>\n",
       "      <td>I don't deserve to live anymore</td>\n",
       "      <td>As simple as that. I'm a complete failure. My ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>LoveArt96</td>\n",
       "      <td>1.454259e+09</td>\n",
       "      <td>43jq7i</td>\n",
       "      <td>Anyone overdosed paracetamol?</td>\n",
       "      <td>I tried one time,10g , but didnt work... Now i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit              author   created_utc      id  \\\n",
       "0  SuicideWatch             tait_sa  1.454254e+09  43jg8v   \n",
       "1  SuicideWatch     Sadnessforevert  1.454255e+09  43jh28   \n",
       "2  SuicideWatch  Thisexistencehurts  1.454257e+09  43jm4b   \n",
       "3  SuicideWatch           Rhexysexy  1.454257e+09  43jnbl   \n",
       "4  SuicideWatch           LoveArt96  1.454259e+09  43jq7i   \n",
       "\n",
       "                                               title  \\\n",
       "0                                           Troubled   \n",
       "1        No friends for over 8 years...I need to die   \n",
       "2  Anyone else out there that would have ended it...   \n",
       "3                    I don't deserve to live anymore   \n",
       "4                      Anyone overdosed paracetamol?   \n",
       "\n",
       "                                            selftext  \n",
       "0  Life is hell. \\r\\n\\r\\nI know that is a common ...  \n",
       "1  Raised in an abusive family, I have had 3 boyf...  \n",
       "2  My family is the only reason I havent killed m...  \n",
       "3  As simple as that. I'm a complete failure. My ...  \n",
       "4  I tried one time,10g , but didnt work... Now i...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, let's go ahead and read in the dataset that we want to analyze.\n",
    "df = pd.read_csv('example_data/social_media_dataset.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d7fc1c1-7246-4df3-b864-16bc3fe8890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's just pull out the texts and put them in a list.\n",
    "texts = df[\"selftext\"].tolist()\n",
    "\n",
    "# metadata that we want to retainfor the texts that we want to analyze\n",
    "text_metadata = {\n",
    "    \"author\": df[\"author\"].tolist(),\n",
    "    \"created_utc\": df[\"created_utc\"].tolist(),\n",
    "    \"post_id\": df[\"id\"].tolist()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d390b995-b5e6-45e0-a294-6705042b1a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████▋                                                         | 44/172 [03:28<07:04,  3.32s/it]"
     ]
    }
   ],
   "source": [
    "# Now, we're off to the races! This will batch-analyze the texts in our dataset, exporting our results into\n",
    "# a sentence-level output file and a document-level output file.\n",
    "\n",
    "#Note that doing a Fisher Z-transform may or may not be desirable, depending on your constructs/archetypes of interest.\n",
    "archetype_quantifier.batch_analyze_to_csv(texts = texts,\n",
    "                                          text_metadata = text_metadata,\n",
    "                                          csv_sent_output_location = 'archetypes_sent.csv',\n",
    "                                          csv_doc_output_location = 'archetypes_doc.csv',\n",
    "                                          append_to_existing_csv = False,\n",
    "                                          output_encoding = 'utf-8-sig',\n",
    "                                          mean_center_vectors=True,\n",
    "                                          fisher_z_transform=False,\n",
    "                                          doc_avgs_exclude_sents_with_WC_less_than=5,\n",
    "                                          doc_level_aggregation_type=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67560bb8-aee5-4156-9d16-3077d7d4ab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also just apply this to individual texts, just in case you want to test things out,\n",
    "# or if you do not need to batch-analyze a dataset like the example above. This also lets\n",
    "# you build your own pipeline around the library, iterating and exporting results however\n",
    "# best suits your needs.\n",
    "from pprint import pprint\n",
    "\n",
    "example_text = \"General Kenobi, you are a bold one. I find your behavior bewildering. Surely you realize you're doomed.\"\n",
    "\n",
    "archetype_quantifier.analyze(example_text,\n",
    "                             mean_center_vectors=True,\n",
    "                             fisher_z_transform=False,)\n",
    "\n",
    "results = archetype_quantifier.results\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Sentence Text: {result.sentence_text}\")\n",
    "    print(f\"Word Count: {result.WC}\")\n",
    "    print(\"Archetype scores:\")\n",
    "    pprint(result.archetype_scores)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e3d1df-5912-4752-a472-a4a840571bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
